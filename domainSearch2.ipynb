{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentencepiece and transformers are installed successfully.\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "print(\"sentencepiece and transformers are installed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 100\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m suggestions\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# def print_suggestions(suggestions):\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m#     for i, domain in enumerate(suggestions, 1):\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m#         # print(f\"{domain}\")\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m suggestions \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_similar_domains\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfreshfruits.lk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# print_suggestions(suggestions)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 76\u001b[0m, in \u001b[0;36mgenerate_similar_domains\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m     12\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are a expert in domain name generation. Return only 5 domain names, nothing else.\u001b[39m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;124mInput Analysis Method:\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124mNow generate exactly 5 domain names for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_input\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124mReturn only the 5 domain names with the extension .lk, one per line, nothing else.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m# inputs = tokenizer(prompt, return_tensors=\"pt\")\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or \"gpt-4o\" for the GPT-4o model\u001b[39;49;00m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# Clean the output\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     \n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# Extract only the domain names\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     suggestions \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Domain name Generator/ds/lib/python3.11/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "# # Load model directly\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-70b-hf\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-70b-hf\")\n",
    "\n",
    "def generate_similar_domains(user_input):\n",
    "#     domain_parts = user_input.split('.')\n",
    "#     domain_name = domain_parts[0]\n",
    "#     extension = domain_parts[1] if len(domain_parts) > 1 else \"\"\n",
    "    \n",
    "    prompt = f\"\"\"You are a expert in domain name generation. Return only 5 domain names, nothing else.\n",
    "\n",
    "Input Analysis Method:\n",
    "1. Split compound words: \"travelguide\" -> [\"travel\", \"guide\"]\n",
    "2. Find synonyms( both sinhala and english ):\n",
    "   - travel: voyage, trip, journey, tour, charika\n",
    "   - guide: helper, assist, expert, advisor\n",
    "3. Create combinations using synonyms\n",
    "4. Add relevant prefixes/suffixes: my-, -hub, -spot, -zone\n",
    "5. Keep domain relevant to original purpose\n",
    "\n",
    "Example Analyses:\n",
    "{{\n",
    "    \"user_input\": \"techblog.com\",\n",
    "    \"word_split\": [\"tech\", \"blog\"],\n",
    "    \"synonyms\": {{\n",
    "        \"tech\": [\"technology\", \"digital\", \"cyber\", \"web\"],\n",
    "        \"blog\": [\"post\", \"write\", \"news\", \"hub\"]\n",
    "    }},\n",
    "    \"AI_response\": [\n",
    "        \"digitalhub.com\",\n",
    "        \"webpost.com\",\n",
    "        \"technews.com\",\n",
    "        \"cyberwrite.com\",\n",
    "        \"techzone.com\"\n",
    "    ]\n",
    "}}\n",
    "\n",
    "{{\n",
    "    \"user_input\": \"smartshop.com\",\n",
    "    \"word_split\": [\"smart\", \"shop\"],\n",
    "    \"synonyms\": {{\n",
    "        \"smart\": [\"clever\", \"wise\", \"intel\", \"bright\"],\n",
    "        \"shop\": [\"store\", \"mart\", \"market\", \"kade\"]\n",
    "    }},\n",
    "    \"AI_response\": [\n",
    "        \"clevermart.com\",\n",
    "        \"wisestore.com\",\n",
    "        \"intelmarket.com\",\n",
    "        \"brightkade.com\",\n",
    "        \"smartmart.com\"\n",
    "    ]\n",
    "}}\n",
    "\n",
    "{{\n",
    "    \"user_input\": \"quickfood.com\",\n",
    "    \"word_split\": [\"quick\", \"food\"],\n",
    "    \"synonyms\": {{\n",
    "        \"quick\": [\"fast\", \"rapid\", \"swift\", \"ikman\"],\n",
    "        \"food\": [\"meal\", \"eat\", \"dish\", \"bite\"]\n",
    "    }},\n",
    "    \"AI_response\": [\n",
    "        \"fastmeal.com\",\n",
    "        \"swiftbite.com\",\n",
    "        \"rapideat.com\",\n",
    "        \"ikmandish.com\",\n",
    "        \"quickbite.com\"\n",
    "    ]\n",
    "}}\n",
    "\n",
    "Now generate exactly 5 domain names for: {user_input}\n",
    "Return only the 5 domain names with the extension .lk, one per line, nothing else.\"\"\"\n",
    "\n",
    "    # inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = openai.Completion.create(\n",
    "        engine=\"gpt-4\",  # or \"gpt-4o\" for the GPT-4o model\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        temperature=1.0,\n",
    "        n=1,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "    # Clean the output\n",
    "    # generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract only the domain names\n",
    "    suggestions = outputs.choices[0].text.strip().split('\\n')\n",
    "    for i, suggestion in enumerate(suggestions):\n",
    "        print(f\"Suggestion {i + 1}: {suggestion}\")\n",
    "\n",
    "    return suggestions\n",
    "\n",
    "# def print_suggestions(suggestions):\n",
    "#     for i, domain in enumerate(suggestions, 1):\n",
    "#         # print(f\"{domain}\")\n",
    "\n",
    "# Example usage\n",
    "suggestions = generate_similar_domains('freshfruits.lk')\n",
    "# print_suggestions(suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
